{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Ch07.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fopitT-qPA1",
        "colab_type": "text"
      },
      "source": [
        "### 程式 7.1 序列式 (Sequential)  v.s Keras 函數式 API："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF6IKe3sqPA3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "362c4c57-8d52-4f10-da03-31404a644f57"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras import layers, Input\n",
        "\n",
        "seq_model = Sequential()\n",
        "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
        "seq_model.add(layers.Dense(32, activation='relu'))\t\t\t\t\t   #1...\n",
        "seq_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "input_tensor = Input(shape=(64,))   #← 建立一個初始張量\n",
        "\n",
        "# 將初始張量傳入 Dense 層得到輸出張量 x\n",
        "x = layers.Dense(32, activation='relu')(input_tensor)\n",
        " \n",
        "# 再將第一層的結果 x 傳入第 2 個 Dense 層得到輸出張量 y                2...\n",
        "y = layers.Dense(32, activation='relu')(x) \n",
        "\n",
        "# 再將第二層的結果 y 傳入最後一個 Dense 層得到最後的輸出張量 output_tensor\n",
        "output_tensor = layers.Dense(10, activation='softmax')(y) \n",
        "\n",
        "# Model 類別 \"用\" 初始的輸入張量和最後的輸出張量來得到模型物件\n",
        "model = Model(input_tensor, output_tensor)\n",
        "model.summary()     # 來看看模型摘要吧！\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP-SHs_qqPA7",
        "colab_type": "text"
      },
      "source": [
        "### 程式 7.2 以函數式 API 實作雙輸入問答模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuOfCcBZqPA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "outputId": "cd6e02d7-e84a-4c54-b4c1-684d898b9133"
      },
      "source": [
        "from keras import Model\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "\n",
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\t\t\t\t\t\t #↓1...                   #↓2...\n",
        "text_input = Input(shape=(None, ), dtype='int32', name='text') \n",
        "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input) #← 3...\n",
        "print(embedded_text.shape)  \t#→ (?, ?, 64)\n",
        "encoded_text = layers.LSTM(32)(embedded_text) #← 4...\n",
        "print(encoded_text.shape)  #\t→ (?, 32)\n",
        "\n",
        "question_input = Input(shape=(None, ), dtype='int32', name='question')\n",
        "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input) #5..\n",
        "print(embedded_question.shape)  \t#→ (?, ?, 32)\n",
        "encoded_question = layers.LSTM(16)(embedded_question)\n",
        "print(encoded_question.shape)  \t#→ (?, 16)\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t#↓6...\n",
        "concatenated = layers.concatenate([encoded_question, encoded_text], axis=-1) \n",
        "print(concatenated.shape)  #→ (?, 48)\n",
        "\n",
        "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated) #← 7...\n",
        "print(answer.shape)  #→ (?, 500) \n",
        "\n",
        "model = Model([text_input, question_input], answer) #← 8...\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "#1. shape = (None, ) 代表不限定張量的 shape 大小, 所以文字輸入可以是可變長度的整數序列。\n",
        "#2. 請注意, 可以選擇是否為輸入命名, 原因為下面程式 7.2 中的訓練方法 2。\n",
        "#3. 將輸入送進嵌入層, 編碼成大小 64 的文字嵌入向量 (處理 「參考文字」輸入)。\n",
        "#4. 再透過 LSTM 層將向量序列編碼成單一個向量\n",
        "#5. 處理「問題」輸入的流程 (與處理「參考文字」輸入的流程相同)\n",
        "#6. 串接編碼後的「問題」和「參考文字」資料 (向量), 將兩份資料合而為一。axis 參數為 -1 代表以輸入的最後一個軸進行串接。\n",
        "#7. 最後增加一個 Dense層 (softmax分類器), 將串接向量送入, 輸出模型的結果張量 answer。\n",
        "#8. 在模型實例化時, 因為有兩個輸入, 所以將它們組成一個 list 一起做為輸入, 而輸出為 answer。\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 64)\n",
            "(?, 32)\n",
            "(?, ?, 32)\n",
            "(?, 16)\n",
            "(?, 48)\n",
            "(?, 500)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "question (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "text (InputLayer)               (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 16)           3136        embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           12416       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 48)           0           lstm_2[0][0]                     \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 500)          24500       concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,000,052\n",
            "Trainable params: 1,000,052\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6e1sXLyqPA-",
        "colab_type": "text"
      },
      "source": [
        "### 程式 7.3 將資料以兩種方式 (list、dict) 傳遞到多輸入模型進行訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aOq2snGqPA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "aa67462f-432c-4171-f9ef-dacfcde3f34a"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "num_samples = 1000\n",
        "max_length = 100\n",
        "\n",
        "# 產生 text 資料：1000 筆, 每筆 100 個字 (數字)\n",
        "text = np.random.randint(1, text_vocabulary_size, \n",
        "                         size=(num_samples, max_length))\n",
        "#  [  [2, 15, 8000,..... 共 100 個], [],....共 1000 筆  ]  \n",
        "#      ↑   ↑    ↑         \n",
        "#     產生 1 ~ 10000 (text_vocabulary_size) 區間的數字 \n",
        "print(text.shape)       # (1000, 100)\n",
        "\n",
        "# 產生 question 資料, 與上面 text 產生方式相同\n",
        "question = np.random.randint(1, question_vocabulary_size, \n",
        "                             size=(num_samples, max_length))\n",
        "print(question.shape)   # (1000, 100)\n",
        "\n",
        "# 產生 answers 資料, 需為 One-hot 編碼, 共 1000 個正確答案\n",
        "answers = np.random.randint(0, 1, size=(num_samples, \n",
        "                                        answer_vocabulary_size))\n",
        "#  [  [0, 1, 1,..... 共 100 個], [],.... 共 1000 筆  ]\n",
        "#      ↑  ↑  ↑         \n",
        "#     產生 0 ~ 1 的數字 \n",
        "# 此為分類器要用的 One-encoding 編碼答案    \n",
        "print(answers.shape)    # (1000, 500)\n",
        "\n",
        "# 訓練方法 1：使用 list 方式送入資料進行擬合 \n",
        "#model.fit([text, question], answers, epochs=10, batch_size=128)\n",
        "# 訓練方法 2：使用 dict 方式送入資料進行擬合, 鍵為 Input 層的名稱, 值為 Numpy 資料\n",
        "model.fit({'text': text, 'question': question}, answers, epochs=10,  batch_size=128)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 100)\n",
            "(1000, 100)\n",
            "(1000, 500)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0000e+00 - acc: 1.0000e-03\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 1.0000e-03\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 1.0000e-03\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 1.0000e-03\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0010\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 1.0000e-03\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 1.0000e-03\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 1.0000e-03\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 1.0000e-03\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 1.0000e-03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe658848898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYzxwOWpqPBC",
        "colab_type": "text"
      },
      "source": [
        "### 程式 7.4 以函數式 API 實作三個輸出結果模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjUdCfanqPBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "7a1f79d8-6cf8-4949-89ae-ac6e4a20e232"
      },
      "source": [
        "from keras import layers, Input\n",
        "from keras.models import Model\n",
        "\n",
        "vocabulary_size = 50000 \t#← 文章大小\n",
        "num_income_groups = 10 \t#← 將收入分成 10 群\n",
        "                            \n",
        "                          # ↓不限定輸入向量的 shape 大小\n",
        "posts_input = Input(shape=(None,), dtype='int32', name='posts') \n",
        "\n",
        "# 用函數式 API 將輸入向量傳入 Embedding 層, 得到維度 256 的嵌入向量\n",
        "embedding_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
        "print(embedding_posts.shape)   # ← (?, ?, 256)\n",
        "\n",
        "# 以下以函數式 API 將嵌入向量傳入一層層之中進行處理\n",
        "x = layers.Conv1D(128, 5, activation='relu')(embedding_posts)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)  \n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "print(x.shape)  #← 走過一連串層之後, x.shape 為 (?, 128)\n",
        "\n",
        "# 接下來將 x 向量分別送入 3 個輸出層。請注意, \n",
        "# 需為輸出層指定名稱(原因請見程式 7.5 中的編譯方法 2)\n",
        "\n",
        "# 預測年紀的輸出層：純量迴歸任務\n",
        "age_prediction = layers.Dense(1, name='age')(x)\n",
        "\n",
        "# 預測收入族群的輸出層多分類任務 (10 類)\n",
        "income_prediction = layers.Dense(num_income_groups, \n",
        "                                 activation='softmax', \n",
        "                                 name='income')(x)\n",
        "# 預測性別的輸出層：二元分類任務\n",
        "gender_prediction = layers.Dense(1, \n",
        "                                 activation='sigmoid', \n",
        "                                 name='gender')(x)\n",
        "\n",
        "# 用輸入向量與輸出向量實例化 Model 物件\n",
        "model = Model(posts_input, \n",
        "              [age_prediction, income_prediction, gender_prediction])\n",
        "                 #↑ 因為輸出向量有 3 個, 所以用 list 來組成\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 256)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "(?, 128)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "posts (InputLayer)              (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, None, 128)    163968      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, None, 256)    164096      max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, None, 256)    327936      conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, None, 256)    0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, None, 256)    327936      max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, None, 256)    327936      conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "income (Dense)                  (None, 10)           1290        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gender (Dense)                  (None, 1)            129         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 14,146,316\n",
            "Trainable params: 14,146,316\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1A1Kz2SqPBF",
        "colab_type": "text"
      },
      "source": [
        "### 程式 7.5 多輸出模型的編譯選項, 指定多重損失函數, 有兩種方式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AllZFAmtqPBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 編譯方式 1 \n",
        "model.compile(optimizer='rmsprop', \n",
        "              loss=['mse',\t\t#← (需照建立層的順序)\n",
        "                    'categorical_crossentropy', \n",
        "                    'binary_crossentropy'])\n",
        "# 編譯方式 2 \n",
        "model.compile(optimizer='rmsprop', \n",
        "              loss={'age': 'mse',\t#← (需為輸出層指定名稱)\n",
        "                    'income': 'categorical_crossentropy', \n",
        "                    'gender': 'binary_crossentropy'})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "E3cgI0AKqPBI",
        "colab_type": "text"
      },
      "source": [
        "### 程式 7.6 孿生 (Siamese) LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35tx74YRqPBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "fcabf3cb-93e9-4460-fd93-9ff963b714c6"
      },
      "source": [
        "from keras import layers\n",
        "from keras import applications\n",
        "from keras import Input\n",
        "\n",
        "# 我們使用 Xception 神經網路的卷積基底 (不包含最上層的分類器) 進行影像的特徵萃取\n",
        "xception_base = applications.Xception(weights=None, include_top=False)\n",
        "\n",
        "# 建立左、右輸入張量 (左、右鏡頭影像), 其 shape 為 (250, 250, 3), 即為 250x250 的彩色影像。\n",
        "left_input = Input(shape=(250, 250, 3))\n",
        "right_input = Input(shape=(250, 250, 3))\n",
        "\n",
        "# 呼叫相同的視覺模型兩次, 也就是將影像張量傳入 Xception 神經網路物件。\n",
        "left_features = xception_base(left_input)\n",
        "right_features = xception_base(right_input)\n",
        "\n",
        "# 萃取出的左、右影像特徵張量 shape = (?, 8, 8, 2048)\n",
        "print(left_features.shape)\n",
        "print(right_features.shape)\n",
        "\n",
        "# 串接左右影像特徵張量, shape = (?, 8, 8, 4096)\n",
        "merged_features = layers.concatenate([left_features, right_features], axis=-1)\n",
        "print(merged_features.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "(?, 8, 8, 2048)\n",
            "(?, 8, 8, 2048)\n",
            "(?, 8, 8, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "9FWaoguNqPBL",
        "colab_type": "text"
      },
      "source": [
        "### 程式 7.7 將使用 TensorBoard 的文字分類模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CouReiAqqPBM",
        "colab_type": "code",
        "colab": {},
        "outputId": "c5c7a75b-be0b-4a59-c467-8cb0e66583c2"
      },
      "source": [
        "import keras \n",
        "from keras import layers\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_features = 2000\n",
        "max_len = 500\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.Embedding(max_features, 128, input_length=max_len, name='embed'))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.MaxPool1D(5))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(layers.Dense(1))\n",
        "model.summary()\n",
        "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embed (Embedding)            (None, 500, 128)          256000    \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 494, 32)           28704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 92, 32)            7200      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 291,937\n",
            "Trainable params: 291,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tV7FsrFqPBP",
        "colab_type": "text"
      },
      "source": [
        "### 程式 7.8 為 TensorBoard 紀錄檔案建立目錄 (Linux 的指令)\n",
        "### $ mkdir my_log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "r4AfZP_eqPBQ",
        "colab_type": "text"
      },
      "source": [
        "### 程式 7.9 使用 TensorBoard 回呼來訓練模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3qbmP7vqPBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [keras.callbacks.TensorBoard(log_dir='my_log_dir', \n",
        "                                         histogram_freq=1, \n",
        "                                         embeddings_freq=1)]\n",
        "\n",
        "history = model.fit(x_train, y_train, \n",
        "                    epochs=20, batch_size=128, \n",
        "                    validation_split=0.2, \n",
        "                    callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "j699dnSBqPBT",
        "colab_type": "text"
      },
      "source": [
        "### 建構輕量的深度可分離卷積神經網路"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1QMQV7-qPBT",
        "colab_type": "code",
        "colab": {},
        "outputId": "9c220d5e-53a8-475a-d947-e941950173bb"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras import layers\n",
        "\n",
        "height = 64\n",
        "width = 64\n",
        "channels = 3\n",
        "num_classes = 10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.SeparableConv2D(32, 3, \n",
        "                                 activation='relu', \n",
        "                                 input_shape=(height, width, channels)))\n",
        "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
        "model.add(layers.MaxPool2D(2))\n",
        "\n",
        "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
        "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2))\n",
        "\n",
        "# model.add(layers.SeparableConv2D(64, 3, activation='relu'))  # 怪怪的\n",
        "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "separable_conv2d_14 (Separab (None, 62, 62, 32)        155       \n",
            "_________________________________________________________________\n",
            "separable_conv2d_15 (Separab (None, 60, 60, 64)        2400      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_16 (Separab (None, 28, 28, 64)        4736      \n",
            "_________________________________________________________________\n",
            "separable_conv2d_17 (Separab (None, 26, 26, 128)       8896      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 128)       0         \n",
            "=================================================================\n",
            "Total params: 16,187\n",
            "Trainable params: 16,187\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARZw44IWqPBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig_MUenKqPBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0uDU6_xqPBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJOiex-8qPBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4SOHWtZqPBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA3TsvdCqPBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-9M1HnSqPBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_UzRPcUqPBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BaJ-F5vqPBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNkAmuUpqPBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-Le83EgqPBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR1mKjwQqPBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JeQyNAZqPB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Wb0G_-qPB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkqgCxhVqPB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}